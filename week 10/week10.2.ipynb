{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP4mrkizhxbagmCyTbojBY7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ryansyaaw/Machine-Learning_2023/blob/main/week%2010/week10.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import TensorFlow"
      ],
      "metadata": {
        "id": "hzZEhb-ZLfoJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "44q8N3mrJQGo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset Shakespeare"
      ],
      "metadata": {
        "id": "4ziTQPdMLgkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "636QjQVALeAd",
        "outputId": "08795b0c-e466-46c8-f1ff-3f2a2124cd48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "rhSLl3uVLpBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "id": "L74vwyPYLq5_",
        "outputId": "fb5741c1-0794-4a50-edbe-b4fc38ba7f1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "id": "pF9kHhPnLu_G",
        "outputId": "59662b42-d603-46e5-9e37-94722f763ee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "id": "rpgp877wLyHW",
        "outputId": "c94231e1-015a-42a6-9bad-8d791753df70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Olah Teks"
      ],
      "metadata": {
        "id": "GvM6EfUPL1zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize Teks"
      ],
      "metadata": {
        "id": "Fxs2vUaFL2am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pecah teks menjadi token"
      ],
      "metadata": {
        "id": "7ZUIWq6hMc1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts=['abcdefg','xyz']\n",
        "chars=tf.strings.unicode_split(example_texts,input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "id": "vf7xP-r9L4Lx",
        "outputId": "07238d02-8f12-4676-9796-a09564cc122b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "buat tf.keras.layers.StringLookup layer"
      ],
      "metadata": {
        "id": "XbRaa1xYMezK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars=tf.keras.layers.StringLookup(vocabulary=list(vocab),mask_token=None)"
      ],
      "metadata": {
        "id": "c0wiis1IMAJ3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "2jWLHvWMMhQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids=ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "id": "GS6mO6-PMI42",
        "outputId": "6a409631-d7b6-4357-f5e6-f8abffdd6629",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode tf.keras.layers.StringLookup(..., invert=True)."
      ],
      "metadata": {
        "id": "LNkhcE5AMtyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "cG-YgFuEMo35"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor"
      ],
      "metadata": {
        "id": "Ei0HkdRFMlgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars=chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "id": "ywznE7fhMylg",
        "outputId": "0ad56563-6d03-42b5-fe6f-f758f30f1b09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string.\n"
      ],
      "metadata": {
        "id": "lqDCElgpM6oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "8j8l09r6M7ge",
        "outputId": "5cb034e5-a5f7-4038-fa5b-83242a43911e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "oElVNF_9NBN_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediksi\n"
      ],
      "metadata": {
        "id": "XJmp6TjaXcQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Trianing Set dan Target"
      ],
      "metadata": {
        "id": "S5_YaQ4HXfDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids =ids_from_chars(tf.strings.unicode_split(text,'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "id": "1FAqQXpGXfgf",
        "outputId": "5d11f7a7-41b0-465a-ca67-4c4b72f74872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset=tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "ZPsl4UlcXlaO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "id": "k5Iom_yBXolO",
        "outputId": "7a068701-bca4-4c63-8b05-d274caf74ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=100"
      ],
      "metadata": {
        "id": "nF5aC7iKXt51"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "id": "ThaMB5qcXyAG",
        "outputId": "bd3b22ea-1510-4317-a80d-1dbd03ed00ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text=sequence[:-1]\n",
        "    target_text=sequence[1:]\n",
        "    return input_text,target_text"
      ],
      "metadata": {
        "id": "Uiv4JsV7X1MB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "id": "Wvgljs9GX-FF",
        "outputId": "d6c01974-13b6-4e51-b13f-75c9d7541dfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "N_urlsB7X_1l"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example,target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "id": "5KUay75hYEkd",
        "outputId": "765694b9-ab1e-4f7f-cb47-5e167c626b4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Batch Training"
      ],
      "metadata": {
        "id": "2wdGMHmmYMg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "Sbz_7ybIYLrJ",
        "outputId": "6f9f8322-c236-4d27-c0ef-f7655798f6cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buat Model"
      ],
      "metadata": {
        "id": "unPOCvo_YQA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "zWRMoWoPYRiZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "toLY5hxBYVSR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "Sdk1Z4McYYCm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Model"
      ],
      "metadata": {
        "id": "55ONTr20YaUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "id": "Cz7Tfp1EYbYD",
        "outputId": "69e1940e-52c3-4d3f-d0a4-9d23179e482e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Xjc9Sl1_Yfxz",
        "outputId": "4dc2b555-de0b-4e80-f744-8f784183fdb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "hvFgNNEhYhsW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "id": "-qN1fQq3YnNy",
        "outputId": "3abe0154-e064-4fb6-ba14-ecb97b90fbd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([34, 38, 19, 23, 53, 15,  4, 13, 29,  3, 59, 37, 17, 54, 57, 13, 53,\n",
              "       46, 33,  7, 34, 20, 47, 29,  5,  7, 40, 23, 14, 19, 50, 63, 51, 62,\n",
              "       42, 58, 65, 23, 18,  8, 40, 55, 30, 42, 30, 28, 63, 19, 17,  7, 33,\n",
              "       12, 60, 56, 15, 63, 40,  2, 37, 38, 25, 45, 24, 15, 19, 11,  5, 54,\n",
              "       40, 50, 15, 57, 40, 15,  3, 17, 53, 30, 19, 60, 13, 43,  9, 32, 59,\n",
              "       23,  5, 62, 10, 59, 43, 52, 49, 45, 65, 25, 51, 60, 23, 33])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "id": "iL6TzDy1YqnR",
        "outputId": "d7144aba-374e-4350-984d-3834abc15e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'n:\\nThe dignity of this act was worth the audience of\\nkings and princes; for by such was it acted.\\n\\nT'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'UYFJnB$?P!tXDor?ngT,UGhP&,aJAFkxlwcszJE-apQcQOxFD,T;uqBxa XYLfKBF:&oakBraB!DnQFu?d.StJ&w3tdmjfzLluJT'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Model**"
      ],
      "metadata": {
        "id": "In-0nMLVYuxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambahan optimizer dan fungsi loss"
      ],
      "metadata": {
        "id": "S8RgJGzOYwqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "W9ED1V92YzVf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "id": "1hjnrr9eY3SQ",
        "outputId": "d6b075bf-250f-40ad-ebce-44e083d3d5cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1901956, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "id": "CVTzgli2Y57H",
        "outputId": "745ad6bf-b082-4a60-bfc0-c46f23255d87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.0357"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "metadata": {
        "id": "uaauAiFRY7ZX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasi Checkpoints"
      ],
      "metadata": {
        "id": "11lBg1NhYyal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "Jp33s7rOY-S6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lakukan Proses Training"
      ],
      "metadata": {
        "id": "NJPVOM5DZEhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=20\n",
        "history=model.fit(dataset,epochs=EPOCHS,callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "LN3F_NiNZBud",
        "outputId": "a3d7008f-4169-4e51-a57f-594d6f0b1894",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 19s 51ms/step - loss: 2.7201\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 49ms/step - loss: 1.9965\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 11s 51ms/step - loss: 1.7257\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 10s 50ms/step - loss: 1.5625\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 1.4606\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 1.3897\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 12s 52ms/step - loss: 1.3369\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.2922\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.2521\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.2130\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 1.1746\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 1.1343\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.0934\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.0493\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.0038\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 13s 58ms/step - loss: 0.9539\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.9036\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 0.8517\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 0.8006\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 0.7499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Teks"
      ],
      "metadata": {
        "id": "6X6xGjdfaepd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "4MjskkH5ag8o"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model=OneStep(model,chars_from_ids,ids_from_chars)"
      ],
      "metadata": {
        "id": "Si_AwJvvbCsA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "id": "rzw3dsTzalE2",
        "outputId": "2f816d1b-a697-4e80-b031-dc5a1dfdf6eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "\n",
            "VOLENCENTIO:\n",
            "I'll draw the crown, what happy rach and happy dates\n",
            "and mine, these words can the subject of a credit\n",
            "And minute his own goodness he is his life; and how\n",
            "should they come?\n",
            "\n",
            "LUCIO:\n",
            "I had rather have done with my daughter with his love\n",
            "than like a sudst be made it off; and yet not she\n",
            "within, sir. Why, his hap the time to come have too much,\n",
            "And not to make the church and adaituon'd for I;\n",
            "And, sir, a son of mine, your fellow to your fair\n",
            "Opposite. Eurteed thou bid company\n",
            "That Bolingbroke this night. Isted the park of darknce\n",
            "How doth with enviour rule and medicines?\n",
            "My birth drops of ten to do him fight against\n",
            "God pretcheel bears make wretched for his deeds:\n",
            "So say we will out, revenge, on me!' pray you,--at dearly next Piligably,\n",
            "I do not king.\n",
            "\n",
            "SICINIUS:\n",
            "He't so, it didst asked was I An as you are:\n",
            "Then, if you head, nor can arier here.\n",
            "Say amen ten thousand me, or else Richmond,\n",
            "Warm a mying advantague and it stand up.'\n",
            "The centre is no greater by that ours,\n",
            "But nat \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.40165114402771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "id": "NOoCNybBbQ1k",
        "outputId": "a387cca1-026c-486a-843f-528758cdab1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nShe dares wrong; I'll call the prince my words\\nhere in Corioli: thou art pung it. I'll kept one,\\nTake him and cities from his querching friends.\\n\\nKING EDWARD IV:\\nBring fare our father far than at young Mars, thou'rt conform;\\nFor troubles no meaten, that my poor human lad\\nWas bleceing warm'd that, my dream or slove\\nAs dodfing from him: this Righbour action\\nMethinks I say he lips and my rind of my son Landamons:\\nThou finds have I, for beauty makes,\\nAs if he looks here lie there. Sweet Isabel, woman, worse!\\n\\nKING HENRY VI:\\nMy Lord of France of Your grace's prince both, you might have been,\\nMy father was a silly servy, a\\nshrink minute from heaven like disgented? speak.\\n\\nQUEEN ELIZABETH:\\nWhat would you make metch?\\n\\nMARCIUS:\\nAy, aught; and, sir, a word of joy.\\n\\nSLY:\\nI kill the gods preserve thee: go, hence it were;\\nThe commons entering shall be even hide;\\nFor how companionship pluck'd or courteous frignds,\\nWhich his own cause I had too, but seldom I\\nno, never a man of joy in sality;\\nOr shut\"\n",
            " b\"ROMEO:\\nWhat comfort Hastings! what commisstions is my father's heir?\\nThen, like a noteful haughty, my liege and much\\nshall eat. And lo, Marcius, help, hell!\\nBut Bianca, gracious Lord of Lancaster\\nThat ever have this Bohim: he owe\\nMy bound of York! I will requite thou hast\\nClerding up. But in the digor's bine,\\nWith promiseth to the judges and my voice:\\nI see a halp ere thou, as if they should be prosperous\\nIn that together were his house: go,\\nSade the fault out, I tesken as you,\\nWho therefore--\\n\\nFROTH:\\nHis thump to thee, or I?\\n\\nTIRCLUCIO:\\nWhere is the court is proud to lose the war\\nThan news to-nour own defance,\\nThat news to make a blaze fathers to his eyes,\\nTo strike King Licentio and his wife,\\nThat common will dry hung and from his socetain'd bring\\nBy any mine advanction and to be so strange?\\nDo: I'll tend them for the most disniph,\\nForget to that his deserving: bear them hence,\\nTo lay on me when you disposity,\\nI told you by my head in thy dreets,\\nBecause the arument make her promotions: pu\"\n",
            " b\"ROMEO:\\nGo, Camillo, that I live unto the crown,\\nWhat our commission wipe mine honour levy,\\nOr else I led past amazed; rest thy right it straight.\\n\\nLADY ANNE:\\nWhen, I see our vantages: but at last\\nIn through the will of person move my head\\nAs heavy as your good queen hath sentenced; away\\nTo think this trunk, by Him that did he make these regard\\nFor ready and like to make me as cheeks\\nWith heigh, and long have left them good horror.\\n\\nFRIAR LAURENCE:\\nShall I remain a voice of stirring up!\\nRights thou demisest to fardin his desire!\\n\\nKING LICHARD II:\\nMy wife is ABill in sight and times the vast.\\n\\nTRANIO:\\nMy banish flesh and febrett could not\\nfor our honour.\\n\\nCLAUDIO:\\nLet me ready farewell: yet much betimes that froward windows\\nOf my purpose.\\n\\nAUFIDIUS:\\nMay it woo here,\\nA word of Milan, ay, for that he that hath suck'd\\nThe sun sends ye not virtuous.\\nBut what, like a salutal liege,\\nAnd not this time and very strangely?\\n\\nAUTOLYCUS:\\nWhy, thou keeps infeit of land;\\nI long to let him there and 'Twere p\"\n",
            " b\"ROMEO:\\nGo needs wake her.\\n\\nFLORIZEL:\\nVery not thyself, fay hold o' the best.\\n\\nBUCKINGHAM:\\nWhat,--'\\nThe devil should thy brother, and my care\\nThan lie, and most consetter: thy sour strange envy, o'er\\nthe strength that way unto my griefs or no.\\nBy minutes, remember whips have I,\\nTremble common peace, I'll give thee order for the parkness.\\nI'll go along with me all this:\\nStop therefore, lett witness of heaven?\\nUnder your helping caparing throats and lances all\\nThe heads of Montague, comfort; what counsel, come back\\nTo hate you from the speech,\\nWhen he would possesser here and then breathe.\\n\\nGREMIO:\\nWhat is the captain, sweet muddon, hence!\\nTell me, what can the son Holves are thou branches,\\nWhich how most law, do not remember this,\\nGive me my son-Poor, Hortons is the way\\nTo give me your suit of that there,\\nEre thrust to bleed the punishment, ere thou ever\\nBehold my Edward so in earth; and here\\nHe clush'd for his presence.\\n\\nKING RICHARD III:\\nI fear, you lorges of yond.\\n\\nLUCIO:\\n\\nISABELLA:\\nHe hang\"\n",
            " b\"ROMEO:\\nFirst, as you know my father service shall stand for any\\nThat shall be brought; why, the pate man Christian spirit,\\nSome little sworn that may be for money: whereon your\\ncounsel with a husband, and will not hear\\nShall I set up my bonnot than the Duke of York.\\n\\nNurse:\\nI did indeed I tempt thy tomb cable.\\n\\nBUCKINGHAM:\\nWell, get the heavy offer of good nor hustandy:\\nBut do not pray?\\n\\nWARWICK:\\nMy banish'd Clarence on my brother lapose\\nTheir assistings, but whiles your lights had been with dull;\\nFor want thou hast a worthy minute how\\nOuthour throad of time, and witness\\nTo answer Taition; they will fill our earth\\nHis givings of his nobal prodigy,\\nFor then thou rarsk her tongue with mercy;\\nMethinks I be rudy and o'er revoice of pined;\\nno parcel now that heard him he?p to see her.\\n\\nQUEEN ELIZABETH:\\nWhy should there giddy makes him hide out this?\\nO royal figure the moral of his pride\\nOf money, father, fled;\\nWhich, look'd on by the holy man?\\nForce me the majesty\\nWhen Itable friends up to the ba\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.851470470428467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ekspor Model Generator"
      ],
      "metadata": {
        "id": "3fydeMb7bWB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "id": "qHakfDWhbXDd",
        "outputId": "8f39b193-d04f-4150-e00d-6ee8c8618c9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7c5064bd7340>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "id": "eYT5H1_NbZiF",
        "outputId": "f8c90a9c-260a-48bb-e16e-503653375011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "What then? I'll not neither hang here;\n",
            "For this on o'er the hang' can frowns; myself\n",
            "With promises \n"
          ]
        }
      ]
    }
  ]
}