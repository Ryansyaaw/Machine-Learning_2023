{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMUzGwctHN3atHnXz612yRB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ryansyaaw/Machine-Learning_2023/blob/main/week%2010/tugas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import TensorFlow"
      ],
      "metadata": {
        "id": "hzZEhb-ZLfoJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "44q8N3mrJQGo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset Shakespeare"
      ],
      "metadata": {
        "id": "4ziTQPdMLgkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "636QjQVALeAd",
        "outputId": "6f0d42c2-d869-45c8-c08b-ddb7e8f3280f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "rhSLl3uVLpBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "id": "L74vwyPYLq5_",
        "outputId": "7ae61853-5957-49e8-cd02-21f845529c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "id": "pF9kHhPnLu_G",
        "outputId": "cc7224fa-4b63-4bc3-a10f-36bb76a2bd08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "id": "rpgp877wLyHW",
        "outputId": "761d3d5b-6482-4c44-c8d9-2fc5970b923f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Olah Teks"
      ],
      "metadata": {
        "id": "GvM6EfUPL1zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize Teks"
      ],
      "metadata": {
        "id": "Fxs2vUaFL2am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pecah teks menjadi token"
      ],
      "metadata": {
        "id": "7ZUIWq6hMc1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts=['abcdefg','xyz']\n",
        "chars=tf.strings.unicode_split(example_texts,input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "id": "vf7xP-r9L4Lx",
        "outputId": "dab5cd2e-2e9a-496c-a946-ad6431c00f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "buat tf.keras.layers.StringLookup layer"
      ],
      "metadata": {
        "id": "XbRaa1xYMezK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars=tf.keras.layers.StringLookup(vocabulary=list(vocab),mask_token=None)"
      ],
      "metadata": {
        "id": "c0wiis1IMAJ3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "2jWLHvWMMhQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids=ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "id": "GS6mO6-PMI42",
        "outputId": "f103a8f2-7189-487c-e9e4-ee9efb7875ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode tf.keras.layers.StringLookup(..., invert=True)."
      ],
      "metadata": {
        "id": "LNkhcE5AMtyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "cG-YgFuEMo35"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor"
      ],
      "metadata": {
        "id": "Ei0HkdRFMlgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars=chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "id": "ywznE7fhMylg",
        "outputId": "b5dbd52e-659a-4732-fd51-c479ad39722b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string.\n"
      ],
      "metadata": {
        "id": "lqDCElgpM6oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "8j8l09r6M7ge",
        "outputId": "1ae128ac-64c2-4d9e-9943-5c83ec89b672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "oElVNF_9NBN_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediksi\n"
      ],
      "metadata": {
        "id": "XJmp6TjaXcQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Trianing Set dan Target"
      ],
      "metadata": {
        "id": "S5_YaQ4HXfDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids =ids_from_chars(tf.strings.unicode_split(text,'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FAqQXpGXfgf",
        "outputId": "7bbe5d92-aace-4572-cfca-ac14f74ab825"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset=tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "ZPsl4UlcXlaO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5Iom_yBXolO",
        "outputId": "e07a6a31-8d6e-481c-e0f8-a21c2397231c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=100"
      ],
      "metadata": {
        "id": "nF5aC7iKXt51"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThaMB5qcXyAG",
        "outputId": "be0af161-86c7-4629-d53f-bd98967ed8ff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text=sequence[:-1]\n",
        "    target_text=sequence[1:]\n",
        "    return input_text,target_text"
      ],
      "metadata": {
        "id": "Uiv4JsV7X1MB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvgljs9GX-FF",
        "outputId": "8b0b2ca9-8dd2-408d-bc4c-5802057427b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "N_urlsB7X_1l"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example,target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KUay75hYEkd",
        "outputId": "91951ff3-a466-48b9-c347-bf6df953d794"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Batch Training"
      ],
      "metadata": {
        "id": "2wdGMHmmYMg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbz_7ybIYLrJ",
        "outputId": "e2bf0338-8938-4e50-e6fe-bf444fba5c7a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buat Model"
      ],
      "metadata": {
        "id": "unPOCvo_YQA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "zWRMoWoPYRiZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "toLY5hxBYVSR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "Sdk1Z4McYYCm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Model"
      ],
      "metadata": {
        "id": "55ONTr20YaUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz7Tfp1EYbYD",
        "outputId": "c453a3e1-6a05-4f85-b484-1d34c0c00189"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjc9Sl1_Yfxz",
        "outputId": "542cce50-4d24-40dd-d9da-ecabcf3d7d8b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "hvFgNNEhYhsW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qN1fQq3YnNy",
        "outputId": "f18839a6-ca6f-4994-9030-120a9e918691"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11, 52, 44, 29, 10, 34, 48,  3,  1, 59, 59, 40, 40, 61, 55, 54, 47,\n",
              "        8, 43, 26, 35,  5, 21, 50,  1, 31, 24, 10, 21, 51, 64, 41,  1, 11,\n",
              "       62,  5, 34, 65, 58,  3, 15,  4, 21, 62, 29, 62, 45, 64, 46, 48, 37,\n",
              "       47, 59, 11, 41,  8, 39, 21, 33, 41, 40, 40, 55, 16, 64, 49, 23, 61,\n",
              "       63, 60, 27, 49, 21, 31, 45, 65, 44, 22, 19, 64, 57, 37, 31, 27, 26,\n",
              "       23, 37, 52, 47,  3, 17, 25, 38, 38, 22, 46, 30, 10, 53, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL6TzDy1YqnR",
        "outputId": "a20049b2-1ae0-411d-d164-de5da6403ea7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b\"tisfied: I'll read enough,\\nWhen I do see the very book indeed\\nWhere all my sins are writ, and that's\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b':meP3Ui!\\nttaavpoh-dMV&Hk\\nRK3Hlyb\\n:w&Uzs!B$HwPwfygiXht:b-ZHTbaapCyjJvxuNjHRfzeIFyrXRNMJXmh!DLYYIgQ3nM'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Model**"
      ],
      "metadata": {
        "id": "In-0nMLVYuxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambahan optimizer dan fungsi loss"
      ],
      "metadata": {
        "id": "S8RgJGzOYwqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "W9ED1V92YzVf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hjnrr9eY3SQ",
        "outputId": "9d096769-d2e0-4c6c-c1ea-9b14add6fab6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1898627, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVTzgli2Y57H",
        "outputId": "c9a309b5-245b-4c33-b92b-fd1cf4962079"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.013725"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "metadata": {
        "id": "uaauAiFRY7ZX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasi Checkpoints"
      ],
      "metadata": {
        "id": "11lBg1NhYyal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "Jp33s7rOY-S6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lakukan Proses Training"
      ],
      "metadata": {
        "id": "NJPVOM5DZEhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=20\n",
        "history=model.fit(dataset,epochs=EPOCHS,callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN3F_NiNZBud",
        "outputId": "8bdfa20d-0bce-4fc2-ad6a-36749b7c007a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 20s 59ms/step - loss: 2.7416\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 1.9995\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 1.7226\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.5576\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.4579\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.3875\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.3349\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.2894\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.2483\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.2084\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.1686\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 13s 59ms/step - loss: 1.1272\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.0844\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.0394\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 13s 61ms/step - loss: 0.9909\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 0.9398\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.8883\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.8336\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 13s 61ms/step - loss: 0.7828\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.7330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Teks"
      ],
      "metadata": {
        "id": "6X6xGjdfaepd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "4MjskkH5ag8o"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model=OneStep(model,chars_from_ids,ids_from_chars)"
      ],
      "metadata": {
        "id": "Si_AwJvvbCsA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzw3dsTzalE2",
        "outputId": "2b2dd556-53d2-433d-f611-af76a336fb06"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "If whom thou know'st, woe speak thou! Tratious in my belly\n",
            "And do not pull them with her speech, to enter penalty,\n",
            "years, the field, do high HOrr'dour thunder;\n",
            "I am the very ring through the wounds\n",
            "Nor now mean to her else,--for informate's sceptre's\n",
            "wailing, to-night she would post unto,\n",
            "Look in a pile, and fires for truthmen: I thought,\n",
            "When I were damned leads me from his body\n",
            "And court of danger, and three parts\n",
            "That such a shamble-tatch fear.\n",
            "\n",
            "DUKE OF YORK:\n",
            "He will know with him? If revenge\n",
            "Tull's fair Siching the swords become my childness nothing else\n",
            "to dincerous eyes to see her after? at least\n",
            "Hath true the first quiet surpect their own virtue.\n",
            "Thine eyes, let them all read.\n",
            "\n",
            "HASTINGS:\n",
            "Men your brother is to death.\n",
            "Can I never saw I never saw'd:\n",
            "Daily dedicate be thy knife to thee;\n",
            "The loving sidet clean us in a raves-loud thing.\n",
            "\n",
            "DUKE OF AUMERLE:\n",
            "Yes; I'll none impose him, go to\n",
            "him up who abul again,\n",
            "He being more reckened to their success.\n",
            "\n",
            "GLOUCESTER:\n",
            "But come to my heart \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.2927935123443604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOoCNybBbQ1k",
        "outputId": "992d0ca3-b2d5-4f78-bb11-2be10be76c0c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nAnd should not burne again unto the Tower,\\nOn purp he rid Henry, we must suggester\\nGo walk: despise and thence then,\\nSince thou art woo'd with the charge,\\nTo keep the idunerate; at away.\\n\\nDUKE OF YORK:\\nThou constants, monarnthy and mine, and at my master's house:\\nThe one perfect I have done. Call help.\\nO mischance of breath I paintent to awaken men,\\nThat know'st thou makes evil my penspecoal\\nOf tyranny. This fellow befiting wome\\nThan forth of love!\\nBut welcome, dear saint,\\nAnd I'll not have showed again Bushy and I ap\\ntheir love oir streets against the servants, there,\\nWill owe my hands my men distiven blessed.\\nThinking on the bellying Bohemia shall,\\nOne Warwick and the father, for that mutiny\\nHeart if you call feel thy formers and my pack;\\nI'll bear my colour's nest, Blacknond\\nClord's temple: I beseech you, fear thus.\\n\\nHERMIONE:\\nWhat's your well?\\n\\nMAMILLIUS:\\nI am peter'd of this.\\n\\nDUKE VINCENTIO:\\nDo she such a court, he knowing dows.\\n\\nKING RICHARD III:\\nThe queen therefore wash your g\"\n",
            " b\"ROMEO:\\nGo, get thee gone,\\nAnd I'll non ever meet him ere he came unto tell\\nWhether the adulteress;\\nWith that argues for swelts are 'trench'd,\\nOur dies, if any her with them; but he\\nhath repeal'd the father, and withal of them,\\nThat there's many mightinance of you\\ncontinue flowers on kiss you in despite of alle:\\nIt mustless I should bound unto their way:\\nBut now I thought my heart concealing\\nHave they made up the dead destrict\\nOf thee all for Edward's wife; there she\\nvery neces all the departure neems to stand: all but\\nfor their feasts, if he give me behind\\nA heart here: the rebels were none such'd\\nThe colour of fire upon their virgin pierce\\nHath done in lineness of his discourse;\\nAnd make her leisure yet express me\\nAs I did still in all my length.\\nWould nob deep as the cause of his choice?\\n\\nBUCKINGHAM:\\nWell, in 'tis a sermand from none when thou art:\\nHe think'st thou, Frinot come,\\nOur fair discourse is. But Harry, I know, not I,\\nIn it before I be alive: if this\\nYour kneving joy in thine own \"\n",
            " b\"ROMEO:\\nHenry within, did Romeo your hands for Tristom dot,\\nOf thee away with child, cut off,\\nWhich should be danger weeping it. Masters, mark his\\nfeel: but I'll not send my garland from him,\\nThat I should fing rud me were stay to-night:\\nAnd there it fellows: you are welcome home:\\nAnd, touch me how I feel a whorimen.\\n\\nSecond Citizen:\\nCaruler to you: speak like a man as come I\\nOverchan so neits of fault, and not revenge\\nTill thou have wasted for't.\\n\\nPERDITA:\\nNo, fie, you shall not cell.\\n\\nANTONIO:\\nThat fated befall me but empty vile pale;\\nBut I did buck: why, I know not what\\nI give him complexion of a mat come hither;\\nOne would think it, Montague in fore.\\n\\nBIANCA:\\nThen, within, gentle Mercyunt there it is so.\\n\\nYORK:\\nI pray his foot. Wilt thou not speak, set down;\\nFor whom it, I'll see the excase.\\n\\nFirst Gentleman:\\nBold, thanks, whensiely waiting I\\nSo, my procks here, man sunder: to make us note,\\nIt bits your country's face, plays cheek thee to thy bed,\\nAnd death, I heep in prison and his heirma\"\n",
            " b\"ROMEO:\\nThe day for the matter. There is morn matter.\\n\\nKATHARINA:\\nWhat, must up when they do defy thee, thou shalt be\\nthy news; and, that's not contented: no, nor none of thy good add\\nRegard to that wretched veil now!\\nWhat, you head that's the wind and familiar is too. He must have go.\\nI rul meteem the instrument to divide\\nThe gaming-of Northumberland. Being truth,\\nFor they accept off again, do not satings,\\nAnd scarr'd the multitud of a truth,\\nGood tops in reverence of spatition, raged\\nUnresolation of the best,\\nAnd mercy then let me have access.\\n\\nShepherd:\\nA parcels but to see\\nThy noble Gentleman born.\\n\\nPOMPEY:\\nDread under-fullow put in victories!\\nWhat, ho! a man that names the noses!\\nThe warrant's wife is mischief: we'll never yet\\nDepateners, well, dead, and hold to me\\nAnd with his events not bid his mutiners,\\nJaliet's both may beware peer.\\n\\nSLY:\\nMarch: me, for I'll prone Romeo is bons like me\\nFrom giving him call mine actor of my blame.\\nDo me be avised, how muffricidst looks\\nSo called indee\"\n",
            " b\"ROMEO:\\nI am a goldge aboait on you!--\\nYet look thou callsly this usurping it.\\n\\nJULIET:\\nYou should, my lord.\\n\\nGLOUCESTER:\\nBut, lords, conceive! what lies your father's?\\nFortunate scalus,\\nThat being publise be rich and her:\\nRomeo, I prithee, do the beggary he is be.\\nHere love so heart to prithee go this shame,\\nThat should not be a peradverla,\\nAn hour she spit, not so hair them not.\\n\\nHASTINGS:\\nGood friend PETER:\\nTowards Lantageat, go endure thee;\\nHe hath the puts of his good fear their dematested.\\nWill't please your honour we must not be here?\\nWhat is your whilst, that self must grieves?\\n\\nThird Citizen:\\nWe'll show his plate, she comes an oath well in his\\ngreater power as tell her dear adiel.\\nThen deny her not tongue-tied manner as they\\nresidence in debt.\\n\\nMARCIUS:\\nLook, what I de-d?'?\\n\\nDUKE VINCENTIO:\\nTruly, sir; and, sir, they are.\\n\\nAUTOLYCUS:\\nI think of Cathey we entaileth thee,\\nHis answer waves, as two and fixty,\\nWhich affection but grief the under theirs,\\nWith times made known thy rube?\\n\\nKA\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.4180800914764404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ekspor Model Generator"
      ],
      "metadata": {
        "id": "3fydeMb7bWB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHakfDWhbXDd",
        "outputId": "f5cdcce6-a034-4e3b-f61b-76016e125691"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f8ed0483d90>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYT5H1_NbZiF",
        "outputId": "e42014f5-d62c-479b-87e5-a7eed33a7ebd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "If you shall know this way?\n",
            "\n",
            "MENENIUS:\n",
            "Not my good labour,\n",
            "Pinceting his advice: my faith in needle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tugas Praktikum**"
      ],
      "metadata": {
        "id": "CdLc11z2eG4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "v5ERkO7TeLfn"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "0a2Eex5JeVDH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "id": "3Yyc4nHgeZR3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "id": "6kyqk8lmeedp",
        "outputId": "7b5a3abb-1b08-440e-af34-33d6a729a8dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 15s 59ms/step - loss: 2.7135\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8ed026df30>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "id": "Hti678f4elwJ",
        "outputId": "76032f72-276a-443a-fa5c-57be68db5207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1801\n",
            "Epoch 1 Batch 50 Loss 2.0368\n",
            "Epoch 1 Batch 100 Loss 1.9778\n",
            "Epoch 1 Batch 150 Loss 1.8827\n",
            "\n",
            "Epoch 1 Loss: 1.9826\n",
            "Time taken for 1 epoch 13.44 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8150\n",
            "Epoch 2 Batch 50 Loss 1.7373\n",
            "Epoch 2 Batch 100 Loss 1.7190\n",
            "Epoch 2 Batch 150 Loss 1.6384\n",
            "\n",
            "Epoch 2 Loss: 1.7026\n",
            "Time taken for 1 epoch 11.00 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5754\n",
            "Epoch 3 Batch 50 Loss 1.5611\n",
            "Epoch 3 Batch 100 Loss 1.5332\n",
            "Epoch 3 Batch 150 Loss 1.4659\n",
            "\n",
            "Epoch 3 Loss: 1.5447\n",
            "Time taken for 1 epoch 11.04 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4789\n",
            "Epoch 4 Batch 50 Loss 1.4824\n",
            "Epoch 4 Batch 100 Loss 1.4603\n",
            "Epoch 4 Batch 150 Loss 1.4381\n",
            "\n",
            "Epoch 4 Loss: 1.4468\n",
            "Time taken for 1 epoch 11.15 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3999\n",
            "Epoch 5 Batch 50 Loss 1.3644\n",
            "Epoch 5 Batch 100 Loss 1.3196\n",
            "Epoch 5 Batch 150 Loss 1.3701\n",
            "\n",
            "Epoch 5 Loss: 1.3803\n",
            "Time taken for 1 epoch 11.30 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3339\n",
            "Epoch 6 Batch 50 Loss 1.3184\n",
            "Epoch 6 Batch 100 Loss 1.3177\n",
            "Epoch 6 Batch 150 Loss 1.3459\n",
            "\n",
            "Epoch 6 Loss: 1.3275\n",
            "Time taken for 1 epoch 20.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2482\n",
            "Epoch 7 Batch 50 Loss 1.2698\n",
            "Epoch 7 Batch 100 Loss 1.2292\n",
            "Epoch 7 Batch 150 Loss 1.2949\n",
            "\n",
            "Epoch 7 Loss: 1.2824\n",
            "Time taken for 1 epoch 11.30 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2145\n",
            "Epoch 8 Batch 50 Loss 1.2553\n",
            "Epoch 8 Batch 100 Loss 1.2420\n",
            "Epoch 8 Batch 150 Loss 1.2407\n",
            "\n",
            "Epoch 8 Loss: 1.2417\n",
            "Time taken for 1 epoch 11.27 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1636\n",
            "Epoch 9 Batch 50 Loss 1.1956\n",
            "Epoch 9 Batch 100 Loss 1.1938\n",
            "Epoch 9 Batch 150 Loss 1.2250\n",
            "\n",
            "Epoch 9 Loss: 1.2020\n",
            "Time taken for 1 epoch 11.38 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1515\n",
            "Epoch 10 Batch 50 Loss 1.1458\n",
            "Epoch 10 Batch 100 Loss 1.1400\n",
            "Epoch 10 Batch 150 Loss 1.1631\n",
            "\n",
            "Epoch 10 Loss: 1.1626\n",
            "Time taken for 1 epoch 11.78 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}